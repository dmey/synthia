{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVBB2_9yS_hO"
   },
   "source": [
    "# Machine learning: correlated multivariate profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: to improve the prediction of a simple ml for predicting radiation flux.\n",
    "# Background: the number of samples (named profiles/columns in the data) are scarce, can we generate\n",
    "#             a larger set of random profiles which stll capture the correclation between differnt quantities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEqua0yYPtrz"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.constants import Stefan_Boltzmann\n",
    "import xarray as xr\n",
    "import gdown\n",
    "from tarfile import TarFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import synthia as syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cloud_optical_depth(ds: xr.Dataset) -> xr.DataArray:\n",
    "    # Constants\n",
    "    g = 9.81 # m/s²\n",
    "    rho_liquid = 1000 # kg/m³\n",
    "    rho_ice = 917 # kg/m³\n",
    "\n",
    "    delta_pressure = ds['pressure_hl'].diff('half_level').rename('delta_pressure')\n",
    "    delta_pressure = delta_pressure.rename({'half_level': 'level'})\n",
    "    \n",
    "    cloud_optical_depth = (ds['q_liquid'] / (rho_liquid * ds['re_liquid']) +\\\n",
    "                     ds['q_ice'] / (rho_ice * ds['re_ice']) ) * delta_pressure / g\n",
    "    return cloud_optical_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_layer_optical_depth(delta_pressure_fl: xr.DataArray, ext_coeff_fl: xr.DataArray):\n",
    "    \"\"\" Compute the layer optical depth from a profile of extinsion coefficients\n",
    "    \"\"\"\n",
    "    layer_optical_depth = ext_coeff_fl * delta_pressure_fl\n",
    "    return layer_optical_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_w8teK7XR4dg"
   },
   "outputs": [],
   "source": [
    "def compute_emissivity(delta_pressure_fl: xr.DataArray, ext_coeff_fl: xr.DataArray) -> xr.DataArray:\n",
    "    diffusivity_factor = 1/np.cos(np.radians(53)) \n",
    "    layer_optical_depth = compute_layer_optical_depth(delta_pressure_fl, ext_coeff_fl)\n",
    "    emissivity = 1 - np.exp(-diffusivity_factor * layer_optical_depth)\n",
    "    return emissivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_plank_func(temperature: xr.DataArray) -> xr.DataArray:\n",
    "    plank_func = Stefan_Boltzmann * temperature**4\n",
    "    return plank_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lw_up_boa(skin_temperature: xr.DataArray,\n",
    "                      lw_emissivity: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"Compute the upwelling longawe flux at BOA\n",
    "    \"\"\"\n",
    "    lw_up_boa = lw_emissivity * compute_plank_func(skin_temperature)\n",
    "    lw_up_boa = lw_up_boa.rename('flux_lw_up_boa')\n",
    "    lw_up_boa.attrs = {'long_name': 'Upward logwave radiation at BOA', 'units': 'W/m2'}\n",
    "    return lw_up_boa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lw_up_profile(temperature_fl: xr.DataArray,\n",
    "                          delta_pressure_fl: xr.DataArray,\n",
    "                          ext_coeff_fl: xr.DataArray,\n",
    "                          flux_at_boa: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"Compute the upwelling longawe flux profile to TOA given flux at BOA\n",
    "    \"\"\"\n",
    "    # Array to store computed fluxes\n",
    "    n_column = len(temperature_fl.column)\n",
    "    n_level = len(temperature_fl.level)\n",
    "    da_flux = xr.DataArray(\n",
    "        np.zeros((n_column, n_level+1)),\n",
    "        dims=('column', 'half_level'), # n_half_level = n_level + 1\n",
    "        name='flux_up_hl',\n",
    "        attrs = {'long_name': 'Upward logwave radiation', \n",
    "                 'units': 'W/m2'}\n",
    "    )\n",
    "\n",
    "    # Assign BC at BOA\n",
    "    da_flux[:, -1] = flux_at_boa\n",
    "    \n",
    "    # Precompute emissivity and plank function as these are independent\n",
    "    emissivity = compute_emissivity(delta_pressure_fl, ext_coeff_fl)\n",
    "    plank_function = compute_plank_func(temperature_fl)\n",
    "\n",
    "    n_half_level = list(range(len(da_flux.half_level))) \n",
    "    # Interate over half levels to TOA\n",
    "    # Revert as TOA is at index zero.\n",
    "    for i in range(da_flux.shape[1] - 1, 0, -1):\n",
    "        da_flux[:, i-1] = da_flux[:, i] * (1 - emissivity[:, i-1]) + plank_function[:, i-1] * emissivity[:, i-1]\n",
    "    return da_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lw_up(temperature_fl: xr.DataArray,\n",
    "                  delta_pressure_fl: xr.DataArray,\n",
    "                  ext_coeff_fl: xr.DataArray,\n",
    "                  skin_temperature: xr.DataArray,\n",
    "                  lw_emissivity: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"Wrapper function to cumpute the full profile from BOA to TOA\n",
    "    \"\"\"\n",
    "    flux_at_boa = compute_lw_up_boa(skin_temperature, lw_emissivity)\n",
    "    lw_up = compute_lw_up_profile(ds, flux_at_boa, opt_depth)\n",
    "    return lw_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Fh36MEJUe8r"
   },
   "source": [
    "## Compute upward longwave radiation from temperature and optical depth\n",
    "\n",
    "Here we use the functions we defined earlier to compute and plot the upward longwave radiation from temperature profiles and optical depth. x-axis indicates pressure levels where 0 is TOA and 137 is BOA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ext_coeff(pressure_fl, opt_depth):\n",
    "    \"\"\" Compute the extinsion coefficient for\n",
    "    the atmosphere given atmospheric pressure\n",
    "    and atmospheric optical depth\n",
    "    \"\"\"\n",
    "    ATM_SCALE_HEIGHT = 300000\n",
    "    A = opt_depth / ATM_SCALE_HEIGHT\n",
    "    ext_coeff = A * np.exp(-ATM_SCALE_HEIGHT / pressure_fl)\n",
    "    return ext_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE1LXGTxSgRL"
   },
   "outputs": [],
   "source": [
    "THIS_DIR = Path.cwd()\n",
    "ds_input = xr.open_dataset(THIS_DIR.parents[1] / 'data' / 'nwp_saf_profiles_in.nc')\n",
    "\n",
    "ds_input['delta_pressure_fl'] = ds_input['pressure_hl'].diff('half_level').rename(half_level='level')\n",
    "\n",
    "opt_depth = 30\n",
    "ds_input['ext_coeff_fl'] = compute_ext_coeff(ds_input['pressure_fl'], opt_depth)\n",
    "\n",
    "input_relevant = ['temperature_fl', # for plank fuction \n",
    "                  'delta_pressure_fl', # for cloud optical depth\n",
    "                  'ext_coeff_fl', # for cloud optical depth\n",
    "                  'skin_temperature', # for flux at BOA\n",
    "                  'lw_emissivity', # for flux at BOA\n",
    "                  #'cloud_fraction' # FIXME: not currently used but of interest as between 0 and 1.\n",
    "]\n",
    "\n",
    "ds_input = ds_input[input_relevant]\n",
    "ds_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_at_boa = compute_lw_up_boa(ds_input['skin_temperature'],\n",
    "                                ds_input['lw_emissivity'])\n",
    "\n",
    "ds_output = compute_lw_up_profile(ds_input['temperature_fl'],\n",
    "                                  ds_input['delta_pressure_fl'],\n",
    "                                  ds_input['ext_coeff_fl'],\n",
    "                                  flux_at_boa)\n",
    "\n",
    "ds_output.mean('column').plot()\n",
    "ds_input_output = xr.merge([ds_input, ds_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xVUSQYDnSr_f",
    "outputId": "56c6c629-e7cc-4b50-e381-3a0e5027de1f"
   },
   "outputs": [],
   "source": [
    "def plot_profile(ds, n_profiles):\n",
    "    for idx in np.random.choice(ds.column, n_profiles):\n",
    "        fig, axs = plt.subplots(1,2, figsize=(5*2,4))\n",
    "        ds['temperature_fl'].isel(column=idx).plot(ax=axs[0], c='r')\n",
    "        ds['flux_up_hl'].isel(column=idx).plot(ax=axs[1], c='k')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_profile(ds_input_output, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm_stats(ds):\n",
    "    stats = {\n",
    "        name : {\n",
    "            'mean' : ds[name].mean(),\n",
    "            'std' : ds[name].std()\n",
    "        } for name in ds\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def normalize_inputs(ds, norm_stats):\n",
    "\n",
    "    def compute_z_score(ds, stats):\n",
    "        return (ds - stats['mean']) / stats['std']\n",
    "\n",
    "    ds_norm = xr.zeros_like(ds)\n",
    "\n",
    "    # These are already in reasonable scale O(1).\n",
    "    quantity_no_norm = ['lw_emissivity']\n",
    "    for quantity in list(ds_norm):\n",
    "        if quantity in quantity_no_norm:\n",
    "            ds_norm[quantity] = ds[quantity]\n",
    "            print(f'Skipping normalization for: {quantity}')\n",
    "        else:\n",
    "            ds_norm[quantity] = compute_z_score(ds[quantity], norm_stats[quantity]) \n",
    "    return ds_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalized_inputs(ds):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "    for quantity in list(ds):\n",
    "        if len(ds[quantity].shape) == 1: # scalars\n",
    "            ds[quantity].plot.hist(ax=ax[0], label=quantity, alpha=0.3)\n",
    "            ax[0].set_ylabel('Count')\n",
    "            ax[0].set_xlabel('Range')\n",
    "            ax[0].legend()\n",
    "        elif len(ds[quantity].shape) == 2: # profiles\n",
    "            ds[quantity].mean('column').plot(ax=ax[1], label=quantity)\n",
    "            ax[1].set_ylabel('Normilized range (Z score)')\n",
    "            ax[1].set_xlabel('Vertical level')\n",
    "            ax[1].set_title('Mean profiles')\n",
    "            ax[1].legend()\n",
    "            ax\n",
    "        else:\n",
    "            raise RuntimeError('Number of dims not supported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true = xr.merge([ds_input, flux_at_boa])\n",
    "X_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_stats = compute_norm_stats(X_true)\n",
    "X_true_norm = normalize_inputs(X_true, norm_stats)\n",
    "X_true_norm = X_true_norm.drop(['delta_pressure_fl', 'lw_emissivity', 'skin_temperature'])\n",
    "plot_normalized_inputs(X_true_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true_norm = X_true_norm\n",
    "X_true_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "X_true_stacked = X_true_norm.to_stacked_array(\"feature\", sample_dims=['column'])\n",
    "y_true = ds_output.sel(half_level=slice(0,-1))\n",
    "display(X_true_stacked, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_true_stacked, y_true, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg = Ridge().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 84\n",
    "plt.plot(range(137), y_test[idx, :])\n",
    "plt.plot(range(137), reg.predict(X_test[idx:idx+1])[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test[:, :], reg.predict(X_test)[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthia.util import to_stacked_array, to_unstacked_dataset\n",
    "import pyvinecopulib as pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data -> split test_train -> copula -> nomrmalize -> \n",
    "# 2. Normilize \n",
    "X_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_true = X_true[['temperature_fl', 'ext_coeff_fl', 'flux_lw_up_boa']]\n",
    "y_true = y_true\n",
    "\n",
    "# Flatten\n",
    "X_true_stacked = X_true.to_stacked_array('feature', sample_dims=['column'])\n",
    "y_true_stacked = y_true.stack(feature=('half_level',))\n",
    "\n",
    "# Split train/test\n",
    "X_true_stacked_train, X_true_stacked_test, \\\n",
    "y_true_stacked_train, y_true_stacked_test = train_test_split(X_true_stacked, \n",
    "                                                             y_true_stacked,\n",
    "                                                             test_size=0.33,\n",
    "                                                             random_state=42)\n",
    "\n",
    "display(X_true_stacked_train, y_true_stacked_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine x and y for copula\n",
    "\n",
    "X_true_train = X_true_stacked_train.to_unstacked_dataset('feature')\n",
    "y_true_train = y_true_stacked_train.unstack('feature')\n",
    "\n",
    "X_y_true_train = xr.merge([X_true_train, y_true_train])\n",
    "X_y_true_train_stacked, stack_info = to_stacked_array(X_y_true_train)\n",
    "\n",
    "X_y_true_train_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterizer = syn.QuantileParameterizer(n_quantiles=100)\n",
    "\n",
    "generator = syn.CopulaDataGenerator(verbose=True)\n",
    "\n",
    "#ctrl = pv.FitControlsVinecop(family_set=[pv.BicopFamily.tll], select_trunc_lvl=True)\n",
    "#generator.fit(X_y_true_train_stacked, copula=syn.VineCopula(controls=ctrl), parameterize_by=parameterizer)\n",
    "generator.fit(X_y_true_train_stacked, copula=syn.GaussianCopula(), parameterize_by=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = X_y_true_train_stacked.shape[0]\n",
    "X_y_synth_train_stacked = generator.generate(n_samples=N_SAMPLES, uniformization_ratio=0, stretch_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_synth_train = to_unstacked_dataset(X_y_synth_train_stacked, stack_info)\n",
    "X_y_synth_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_synth_train = X_y_synth_train\n",
    "X_synth_train = X_y_synth_train.drop('flux_up_hl')\n",
    "y_synth_train = X_y_synth_train[['flux_up_hl']]\n",
    "display(X_synth_train, y_synth_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in np.random.choice(X_y_synth_train.column, 100): \n",
    "    X_y_synth_train['flux_up_hl'].sel(column=column).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in np.random.choice(y_true.column, 100): \n",
    "    X_true['ext_coeff_fl'].sel(column=column).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in np.random.choice(y_true.column, 100): \n",
    "    y_true.sel(column=column).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_synth_train_stacked, stack_info = to_stacked_array(X_synth_train)\n",
    "#y_synth_train_stacked, stack_info = to_stacked_array(y_synth_train)\n",
    "X_synth_train_norm = normalize_inputs(X_synth_train, norm_stats)\n",
    "X_synth_train_norm_stacked = X_synth_train_norm.to_stacked_array('feature', sample_dims=['column'])\n",
    "y_synth_train_stacked = y_synth_train.to_stacked_array('feature', sample_dims=['column'])\n",
    "reg = Ridge().fit(X_synth_train_norm_stacked, y_synth_train_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5\n",
    "plt.plot(range(137), y_test[idx, :], label='true')\n",
    "plt.plot(range(137), reg.predict(X_test[idx:idx+1])[0, :])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Ridge().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "calc-lw-up.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
