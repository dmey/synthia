{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import psychrolib as psy\n",
    "\n",
    "import synthia as syn\n",
    "from synthia import util\n",
    "\n",
    "import pyvinecopulib as pv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papermill parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged `parameters` (see View -> Cell Toolbar -> Tags).\n",
    "test_size = 9000\n",
    "train_size = 100\n",
    "factor_synthetic = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Given:\n",
    "- Real data with multiple quantities\n",
    "- Normalization method\n",
    "- Train / test split of real data\n",
    "- Regression problem\n",
    "- ML model trained on real data\n",
    "- Error metrics for ML model\n",
    "\n",
    "Question:\n",
    "- Can the ML error metrics be improved by training with additional synthetic data?\n",
    "\n",
    "Method:\n",
    "- Fit Copula on training data\n",
    "- Generate synthetic training data\n",
    "- Re-train ML model on real + synthetic data\n",
    "- Compute error metrics for ML model\n",
    "- Compare against original error metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data with multiple quantities\n",
    "\n",
    "Instead of using an existing dataset, we compute our own using a simple physical formula.\n",
    "See the plot below that shows all quantities in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy.SetUnitSystem(psy.SI)\n",
    "\n",
    "n_points = 100\n",
    "tdb = np.linspace(1, 150, num=n_points)\n",
    "rh = np.linspace(1e-2, 1, num=n_points)\n",
    "\n",
    "grid = np.meshgrid(tdb, rh)\n",
    "tdp = psy.GetTDewPointFromRelHum(grid[0], grid[1])\n",
    "\n",
    "ds_grid = xr.Dataset({\n",
    "    'tdb': (['i', 'j'], grid[0]),\n",
    "    'rh': (['i', 'j'], grid[1]),\n",
    "    'tdp': (['i', 'j'], tdp),\n",
    "})\n",
    "\n",
    "# Flatten the i/j grid dimensions into a single sample dimension for use in ML models.\n",
    "ds_samples = ds_grid.stack(sample=('i', 'j'))\n",
    "ds_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "cp = ax.contourf(ds_grid['tdb'], ds_grid['rh'], ds_grid['tdp'])\n",
    "fig.colorbar(cp)\n",
    "ax.set_title('Dew point temperature in °C')\n",
    "ax.set_xlabel('Dry bulb temperature in °C')\n",
    "ax.set_ylabel('Relative Humidity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_samples_norm, norm_stats = util.to_normalized_dataset(ds_samples)\n",
    "ds_samples_norm.to_dataframe().hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / test split of real data\n",
    "\n",
    "In this example, we split the data as follows:\n",
    "\n",
    "- Test data = 9000 samples\n",
    "- Train data = out of the remaining 1000 samples, subset 100 or 500 or 1000 samples\n",
    "\n",
    "See parameters cell at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test = util.train_test_split_dataset(ds_samples_norm, test_size=test_size, dim='sample', shuffle=True)\n",
    "ds_train = ds_train.isel(sample=slice(train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_data(ds_train, ds_test, train_label='train', test_label='test'):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "    axs[0].scatter(ds_train['tdb'], ds_train['tdp'], label=train_label)\n",
    "    axs[0].scatter(ds_test['tdb'], ds_test['tdp'], label=test_label, alpha=0.1)\n",
    "    axs[1].scatter(ds_train['rh'], ds_train['tdp'], label=train_label)\n",
    "    axs[1].scatter(ds_test['rh'], ds_test['tdp'], label=test_label, alpha=0.1)\n",
    "\n",
    "    axs[0].set_xlabel('Dry bulb temperature in °C')\n",
    "    axs[0].set_ylabel('Dew point temperature in °C')\n",
    "    axs[1].set_xlabel('Relative Humidity')\n",
    "    axs[1].set_ylabel('Dew point temperature in °C')\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    \n",
    "plot_train_test_data(util.to_unnormalized_dataset(ds_train, norm_stats), \n",
    "                     util.to_unnormalized_dataset(ds_test, norm_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression problem\n",
    "\n",
    "Given dry bulb temperature (tdb) and relative humidity (rh), predict dew point temperature (tdp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars = ['tdb', 'rh']\n",
    "y_var = 'tdp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model trained on real data\n",
    "To establish a baseline for later comparison, we now train the ML model on the real data solving the stated regression problem.\n",
    "In this sample, we use the standard MLP model from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_model(train, test, X_vars, y_var, epochs, iterations):\n",
    "    X_train, _ = util.to_stacked_array(train[X_vars])\n",
    "    X_test, _ = util.to_stacked_array(test[X_vars])\n",
    "    y_train = train[y_var]\n",
    "    y_test = test[y_var]\n",
    "\n",
    "    results = []\n",
    "    for i in tqdm(range(iterations)):\n",
    "        model = MLPRegressor(max_iter=epochs)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        results.append({\n",
    "            'r2': model.score(X_test, y_test),\n",
    "            'mse': mean_squared_error(y_test, y_pred_test)\n",
    "        })\n",
    "    results = pd.DataFrame(results)\n",
    "    return results, y_pred_test\n",
    "\n",
    "epochs = 1000\n",
    "iterations = 20\n",
    "\n",
    "results, y_pred_test = train_ml_model(ds_train, ds_test, X_vars, y_var, epochs, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot (predictions of last trained model only!)\n",
    "def plot_true_vs_pred(true, pred):\n",
    "    plt.scatter(pred, true, alpha=0.1)\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('true')\n",
    "    y_min, y_max = true.min(), true.max()\n",
    "    plt.plot([y_min, y_max], [y_min, y_max], color='black')\n",
    "\n",
    "plot_true_vs_pred(ds_test[y_var], y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error metrics for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_metrics(df_metrics):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "    df_metrics[['mse']].boxplot(ax=axs[0])\n",
    "    df_metrics[['r2']].boxplot(ax=axs[1])\n",
    "\n",
    "plot_error_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create synthetic training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic(data, n_samples, n_quantiles, uniformization_ratio, stretch_factor):\n",
    "    generator = syn.CopulaDataGenerator(verbose=True)\n",
    "    parameterizer = syn.QuantileParameterizer(n_quantiles=n_quantiles)\n",
    "    ctrl = pv.FitControlsVinecop(num_threads=2)\n",
    "    generator.fit(data, copula=syn.VineCopula(controls=ctrl), parameterize_by=parameterizer)\n",
    "    #generator.fit(data, copula=syn.GaussianCopula(), parameterize_by=parameterizer)\n",
    "    synthetic = generator.generate(n_samples=n_samples, uniformization_ratio=uniformization_ratio, stretch_factor=stretch_factor)\n",
    "    return synthetic\n",
    "\n",
    "ds_synthetic = create_synthetic(ds_train, n_samples=ds_train.dims['sample']*factor_synthetic,\n",
    "                                n_quantiles=ds_train.dims['sample'],\n",
    "                                uniformization_ratio=0., stretch_factor=1)\n",
    "\n",
    "ds_train_with_synthetic = xr.concat([ds_synthetic, ds_train.reset_index('sample', drop=True)], dim='sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test_data(util.to_unnormalized_dataset(ds_train_with_synthetic, norm_stats),\n",
    "                     util.to_unnormalized_dataset(ds_test, norm_stats), train_label='train + synthetic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model trained on real + synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_synthetic, y_pred_test_synthetic = train_ml_model(ds_train_with_synthetic, ds_test, X_vars, y_var, epochs, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot (predictions of last trained model only!)\n",
    "plot_true_vs_pred(ds_test[y_var], y_pred_test_synthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error metrics for ML model trained on real + synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_metrics(results_synthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of error metrics to original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
