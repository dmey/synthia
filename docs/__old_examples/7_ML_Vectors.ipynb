{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVBB2_9yS_hO"
   },
   "source": [
    "# Machine learning: correlated multivariate profiles\n",
    "\n",
    "Goal: to improve the prediction of a simple ml for predicting radiation flux.\n",
    "\n",
    "Background: the number of samples (named profiles/columns in the data) are scarce, can we generate a larger set of random profiles which stll capture the correclation between differnt quantities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEqua0yYPtrz"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.constants import Stefan_Boltzmann\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import synthia as syn\n",
    "from synthia.util import to_stacked_array, to_unstacked_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cloud_optical_depth(ds: xr.Dataset) -> xr.DataArray:\n",
    "    # Constants\n",
    "    g = 9.81 # m/s²\n",
    "    rho_liquid = 1000 # kg/m³\n",
    "    rho_ice = 917 # kg/m³\n",
    "\n",
    "    delta_pressure = ds['pressure_hl'].diff('half_level').rename('delta_pressure')\n",
    "    delta_pressure = delta_pressure.rename({'half_level': 'level'})\n",
    "    \n",
    "    cloud_optical_depth = (ds['q_liquid'] / (rho_liquid * ds['re_liquid']) +\\\n",
    "                     ds['q_ice'] / (rho_ice * ds['re_ice']) ) * delta_pressure / g\n",
    "    return cloud_optical_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_layer_optical_depth(delta_pressure_fl: xr.DataArray, ext_coeff_fl: xr.DataArray):\n",
    "    \"\"\" Compute the layer optical depth from a profile of extinsion coefficients\n",
    "    \"\"\"\n",
    "    layer_optical_depth = ext_coeff_fl * delta_pressure_fl\n",
    "    return layer_optical_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_w8teK7XR4dg"
   },
   "outputs": [],
   "source": [
    "def compute_emissivity(delta_pressure_fl: xr.DataArray, ext_coeff_fl: xr.DataArray) -> xr.DataArray:\n",
    "    diffusivity_factor = 1/np.cos(np.radians(53)) \n",
    "    layer_optical_depth = compute_layer_optical_depth(delta_pressure_fl, ext_coeff_fl)\n",
    "    emissivity = 1 - np.exp(-diffusivity_factor * layer_optical_depth)\n",
    "    return emissivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_plank_func(temperature: xr.DataArray) -> xr.DataArray:\n",
    "    plank_func = Stefan_Boltzmann * temperature**4\n",
    "    return plank_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lw_up_boa(skin_temperature: xr.DataArray,\n",
    "                      lw_emissivity: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"Compute the upwelling longawe flux at BOA\n",
    "    \"\"\"\n",
    "    lw_up_boa = lw_emissivity * compute_plank_func(skin_temperature)\n",
    "    lw_up_boa = lw_up_boa.rename('flux_lw_up_boa')\n",
    "    lw_up_boa.attrs = {'long_name': 'Upward logwave radiation at BOA', 'units': 'W/m2'}\n",
    "    return lw_up_boa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lw_up_profile(temperature_fl: xr.DataArray,\n",
    "                          delta_pressure_fl: xr.DataArray,\n",
    "                          ext_coeff_fl: xr.DataArray,\n",
    "                          flux_at_boa: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"Compute the upwelling longawe flux profile to TOA given flux at BOA\n",
    "    \"\"\"\n",
    "    # Array to store computed fluxes\n",
    "    n_column = len(temperature_fl.column)\n",
    "    n_level = len(temperature_fl.level)\n",
    "    da_flux = xr.DataArray(\n",
    "        np.zeros((n_column, n_level+1)),\n",
    "        dims=('column', 'half_level'), # n_half_level = n_level + 1\n",
    "        name='flux_up_hl',\n",
    "        attrs = {'long_name': 'Upward logwave radiation', \n",
    "                 'units': 'W/m2'}\n",
    "    )\n",
    "\n",
    "    # Assign BC at BOA\n",
    "    da_flux[:, -1] = flux_at_boa\n",
    "    \n",
    "    # Precompute emissivity and plank function as these are independent\n",
    "    emissivity = compute_emissivity(delta_pressure_fl, ext_coeff_fl)\n",
    "    plank_function = compute_plank_func(temperature_fl)\n",
    "\n",
    "    n_half_level = list(range(len(da_flux.half_level))) \n",
    "    # Interate over half levels to TOA\n",
    "    # Revert as TOA is at index zero.\n",
    "    for i in range(da_flux.shape[1] - 1, 0, -1):\n",
    "        da_flux[:, i-1] = da_flux[:, i] * (1 - emissivity[:, i-1]) + plank_function[:, i-1] * emissivity[:, i-1]\n",
    "    return da_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lw_up(temperature_fl: xr.DataArray,\n",
    "                  delta_pressure_fl: xr.DataArray,\n",
    "                  ext_coeff_fl: xr.DataArray,\n",
    "                  skin_temperature: xr.DataArray,\n",
    "                  lw_emissivity: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"Wrapper function to cumpute the full profile from BOA to TOA\n",
    "    \"\"\"\n",
    "    flux_at_boa = compute_lw_up_boa(skin_temperature, lw_emissivity)\n",
    "    lw_up = compute_lw_up_profile(temperature_fl,\n",
    "                                  delta_pressure_fl,\n",
    "                                  ext_coeff_fl,\n",
    "                                  flux_at_boa)\n",
    "    return lw_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Fh36MEJUe8r"
   },
   "source": [
    "## Compute upward longwave radiation from temperature and optical depth\n",
    "\n",
    "Here we use the functions we defined earlier to compute and plot the upward longwave radiation from temperature profiles and optical depth. x-axis indicates pressure levels where 0 is TOA and 137 is BOA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ext_coeff(pressure_fl, opt_depth):\n",
    "    \"\"\" Compute the extinsion coefficient for\n",
    "    the atmosphere given atmospheric pressure\n",
    "    and atmospheric optical depth\n",
    "    \"\"\"\n",
    "    ATM_SCALE_HEIGHT = 300000\n",
    "    A = opt_depth / ATM_SCALE_HEIGHT\n",
    "    ext_coeff = A * np.exp(-ATM_SCALE_HEIGHT / pressure_fl)\n",
    "    return ext_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE1LXGTxSgRL"
   },
   "outputs": [],
   "source": [
    "THIS_DIR = Path.cwd()\n",
    "ds_input = xr.open_dataset(THIS_DIR.parents[1] / 'data' / 'nwp_saf_profiles_in.nc')\n",
    "\n",
    "ds_input['delta_pressure_fl'] = ds_input['pressure_hl'].diff('half_level').rename(half_level='level')\n",
    "\n",
    "opt_depth = 30\n",
    "ds_input['ext_coeff_fl'] = compute_ext_coeff(ds_input['pressure_fl'], opt_depth)\n",
    "\n",
    "input_relevant = [\n",
    "    'temperature_fl', # for plank fuction \n",
    "    'delta_pressure_fl', # for cloud optical depth\n",
    "    'ext_coeff_fl', # for cloud optical depth\n",
    "    'skin_temperature', # for flux at BOA\n",
    "    'lw_emissivity' # for flux at BOA\n",
    "]\n",
    "\n",
    "ds_true_in = ds_input[input_relevant]\n",
    "ds_true_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_true_out = compute_lw_up(ds_true_in['temperature_fl'],\n",
    "                            ds_true_in['delta_pressure_fl'],\n",
    "                            ds_true_in['ext_coeff_fl'],\n",
    "                            ds_true_in['skin_temperature'],\n",
    "                            ds_true_in['lw_emissivity'])\n",
    "\n",
    "ds_true_out.mean('column').plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xVUSQYDnSr_f",
    "outputId": "56c6c629-e7cc-4b50-e381-3a0e5027de1f"
   },
   "outputs": [],
   "source": [
    "def plot_profile(ds_in, ds_out, n_profiles):\n",
    "    for idx in np.random.choice(ds_in.column, n_profiles):\n",
    "        fig, axs = plt.subplots(1,2, figsize=(5*2,4))\n",
    "        ds_in['temperature_fl'].isel(column=idx).plot(ax=axs[0], c='r')\n",
    "        ds_out.isel(column=idx).plot(ax=axs[1], c='k')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_profile(ds_true_in, ds_true_out, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning: baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm_stats(ds):\n",
    "    stats = {\n",
    "        name : {\n",
    "            'mean' : ds[name].mean(),\n",
    "            'std' : ds[name].std()\n",
    "        } for name in ds\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def normalize_inputs(ds, norm_stats):\n",
    "\n",
    "    def compute_z_score(ds, stats):\n",
    "        return (ds - stats['mean']) / stats['std']\n",
    "\n",
    "    ds_norm = xr.zeros_like(ds)\n",
    "\n",
    "    # These are already in reasonable scale O(1).\n",
    "    quantity_no_norm = ['lw_emissivity']\n",
    "    for quantity in list(ds_norm):\n",
    "        if quantity in quantity_no_norm:\n",
    "            ds_norm[quantity] = ds[quantity]\n",
    "            print(f'Skipping normalization for: {quantity}')\n",
    "        else:\n",
    "            ds_norm[quantity] = compute_z_score(ds[quantity], norm_stats[quantity]) \n",
    "    return ds_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalized_inputs(ds):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "    for quantity in list(ds):\n",
    "        if len(ds[quantity].shape) == 1: # scalars\n",
    "            ds[quantity].plot.hist(ax=ax[0], label=quantity, alpha=0.3)\n",
    "            ax[0].set_ylabel('Count')\n",
    "            ax[0].set_xlabel('Range')\n",
    "            ax[0].legend()\n",
    "        elif len(ds[quantity].shape) == 2: # profiles\n",
    "            ds[quantity].mean('column').plot(ax=ax[1], label=quantity)\n",
    "            ax[1].set_ylabel('Normilized range (Z score)')\n",
    "            ax[1].set_xlabel('Vertical level')\n",
    "            ax[1].set_title('Mean profiles')\n",
    "            ax[1].legend()\n",
    "            ax\n",
    "        else:\n",
    "            raise RuntimeError('Number of dims not supported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_stats = compute_norm_stats(ds_true_in)\n",
    "X_true_norm = normalize_inputs(ds_true_in, norm_stats)\n",
    "plot_normalized_inputs(X_true_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "X_true_stacked_norm, stack_info = to_stacked_array(X_true_norm)\n",
    "\n",
    "# Train/test split\n",
    "X_true_train_norm, X_true_test_norm, y_true_train_norm, y_true_test_norm = train_test_split(X_true_stacked_norm, \n",
    "                                                                        ds_true_out, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_baseline = Ridge()\n",
    "model_baseline.fit(X_true_train_norm, y_true_train_norm)\n",
    "y_pred_test_norm = xr.DataArray(model_baseline.predict(X_true_test_norm), dims=['column', 'half_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_baseline.score(X_true_test_norm, y_true_test_norm)\n",
    "print(score);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in np.random.choice(y_true_test_norm.column, 10):\n",
    "    y_true_test_norm.sel(column=column).plot(label='true')\n",
    "    y_pred_test_norm.sel(column=column).plot(label='pred')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use a copula to generate more samples to try improve the results\n",
    "# 1. Split train/test data\n",
    "# 2. Fit copula and generate synthetic samples for the model inputs only\n",
    "# 3. Run physical model\n",
    "# 4. Evaluate the modle with ML model as used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we need to split the test train first -- we will not use the y\n",
    "\n",
    "# Flatten\n",
    "X_true_stacked, stack_info = to_stacked_array(ds_true_in)\n",
    "X_true_stacked\n",
    "\n",
    "# Train/test split\n",
    "X_true_train, X_true_test, y_true_train, y_true_test = train_test_split(X_true_stacked, \n",
    "                                                                        ds_true_out, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterizer = syn.QuantileParameterizer(n_quantiles=100)\n",
    "generator = syn.CopulaDataGenerator(verbose=True)\n",
    "generator.fit(X_true_train, copula=syn.GaussianCopula(), parameterize_by=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X_true_train.shape[0] * 2 # Twice as many\n",
    "X_synth_train = generator.generate(n_samples=n_samples, uniformization_ratio=0, stretch_factor=1)\n",
    "X_synth_train = to_unstacked_dataset(X_synth_train, stack_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_synth_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_synth_out = compute_lw_up(X_synth_train['temperature_fl'],\n",
    "                            X_synth_train['delta_pressure_fl'],\n",
    "                            X_synth_train['ext_coeff_fl'],\n",
    "                            X_synth_train['skin_temperature'],\n",
    "                            X_synth_train['lw_emissivity'])\n",
    "\n",
    "ds_synth_out.mean('column').plot();\n",
    "ds_true_out.mean('column').plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we normilize and train the synthetic samples instead\n",
    "\n",
    "norm_stats = compute_norm_stats(X_synth_train)\n",
    "X_synth_norm = normalize_inputs(X_synth_train, norm_stats)\n",
    "plot_normalized_inputs(X_synth_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "X_synth_stacked, stack_info = to_stacked_array(X_synth_norm)\n",
    "\n",
    "# Train/test split\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth_stacked, \n",
    "                                                                        ds_synth_out, test_size=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_synth = Ridge()\n",
    "model_synth.fit(X_synth_train, y_synth_train)\n",
    "y_synth_pred_test = xr.DataArray(model_synth.predict(X_true_test_norm), dims=['column', 'half_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_synth.score(X_true_test_norm, y_true_test_norm)\n",
    "print(score);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in np.random.choice(y_true_test.column, 10):\n",
    "    y_true_test_norm.sel(column=column).plot(label='true')\n",
    "    y_synth_pred_test.sel(column=column).plot(label='pred')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "calc-lw-up.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
